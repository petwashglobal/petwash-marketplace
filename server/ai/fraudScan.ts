/**
 * AI FRAUD AND ANOMALY DETECTION
 * Gemini AI-Powered Transaction Security
 * 
 * Features:
 * - Real-time fraud scoring for all transactions
 * - Pattern detection for suspicious activity
 * - Automatic security team alerts
 * - Blockchain-style audit trail
 */

import { GoogleGenerativeAI } from '@google/generative-ai';
import { db } from '../db';
import { sql } from 'drizzle-orm';
import { logger } from '../lib/logger';
import NotificationService from '../services/NotificationService';

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || '');

/**
 * Transaction data for fraud analysis
 */
interface Transaction {
  id: string;
  userId: string;
  userEmail: string;
  amountCents: number;
  currency: string;
  type: string; // 'wash', 'booking', 'package', 'loyalty'
  ip: string;
  userAgent?: string;
  location?: string;
  timestamp: Date;
}

/**
 * Fraud analysis result
 */
interface FraudAnalysis {
  riskScore: number; // 0-100 (0=safe, 100=fraud)
  riskLevel: 'low' | 'medium' | 'high' | 'critical';
  reasons: string[];
  recommendedAction: 'approve' | 'review' | 'block';
}

/**
 * Analyze transaction for fraud using Gemini AI
 */
async function analyzeWithAI(tx: Transaction): Promise<FraudAnalysis> {
  try {
    const model = genAI.getGenerativeModel({ model: 'gemini-2.5-flash' });
    
    const prompt = `You are a fraud detection AI for Pet Washâ„¢ payment platform.

Analyze this transaction for fraud risk:

Transaction ID: ${tx.id}
User: ${tx.userEmail}
Amount: ${(tx.amountCents / 100).toFixed(2)} ${tx.currency}
Type: ${tx.type}
IP Address: ${tx.ip}
User Agent: ${tx.userAgent || 'N/A'}
Location: ${tx.location || 'Unknown'}
Time: ${tx.timestamp.toISOString()}

Fraud indicators to check:
1. Unusually large amounts for pet services
2. Rapid succession of transactions (velocity)
3. Suspicious IP addresses or proxies
4. Mismatched location patterns
5. Unusual transaction times (3 AM purchases)
6. High-risk countries or regions
7. Pattern anomalies vs user's history

Return JSON only:
{
  "riskScore": <0-100>,
  "riskLevel": "<low|medium|high|critical>",
  "reasons": ["reason1", "reason2"],
  "recommendedAction": "<approve|review|block>"
}`;

    const result = await model.generateContent(prompt);
    const responseText = result.response.text();
    
    // Extract JSON from response
    const jsonMatch = responseText.match(/\{[\s\S]*\}/);
    if (!jsonMatch) {
      throw new Error('Invalid AI response format');
    }
    
    const analysis: FraudAnalysis = JSON.parse(jsonMatch[0]);
    
    logger.info('[FraudScan] AI analysis complete', {
      txId: tx.id,
      riskScore: analysis.riskScore,
      riskLevel: analysis.riskLevel,
    });
    
    return analysis;
    
  } catch (error: any) {
    logger.error('[FraudScan] AI analysis failed', {
      txId: tx.id,
      error: error.message,
    });
    
    // Fallback: Rule-based scoring
    return fallbackRuleBasedScoring(tx);
  }
}

/**
 * Fallback rule-based fraud scoring (if AI fails)
 */
function fallbackRuleBasedScoring(tx: Transaction): FraudAnalysis {
  let riskScore = 0;
  const reasons: string[] = [];
  
  // Rule 1: Unusually large amounts (>500 ILS for pet services)
  const amountILS = tx.amountCents / 100;
  if (amountILS > 500) {
    riskScore += 30;
    reasons.push(`High amount: â‚ª${amountILS.toFixed(2)}`);
  }
  
  // Rule 2: Round numbers might indicate testing
  if (amountILS % 100 === 0) {
    riskScore += 10;
    reasons.push('Suspiciously round amount');
  }
  
  // Rule 3: Check for localhost/development IPs
  if (tx.ip === '127.0.0.1' || tx.ip?.startsWith('192.168.')) {
    riskScore += 20;
    reasons.push('Local/internal IP address');
  }
  
  // Determine risk level
  let riskLevel: 'low' | 'medium' | 'high' | 'critical';
  let recommendedAction: 'approve' | 'review' | 'block';
  
  if (riskScore < 30) {
    riskLevel = 'low';
    recommendedAction = 'approve';
  } else if (riskScore < 60) {
    riskLevel = 'medium';
    recommendedAction = 'review';
  } else if (riskScore < 80) {
    riskLevel = 'high';
    recommendedAction = 'review';
  } else {
    riskLevel = 'critical';
    recommendedAction = 'block';
  }
  
  return {
    riskScore,
    riskLevel,
    reasons,
    recommendedAction,
  };
}

/**
 * Notify security team about suspicious transaction
 */
async function notifySecurity(tx: Transaction, analysis: FraudAnalysis) {
  try {
    const securityEmails = process.env.SECURITY_ALERT_EMAILS?.split(',') || 
      ['security@petwash.co.il'];
    
    await NotificationService.sendEmail({
      to: securityEmails,
      subject: `ðŸš¨ ${analysis.riskLevel.toUpperCase()} Risk Transaction Detected`,
      template: 'fraud-alert',
      data: {
        transaction: tx,
        analysis,
        timestamp: new Date().toISOString(),
      },
    });
    
    logger.info('[FraudScan] Security team notified', {
      txId: tx.id,
      riskLevel: analysis.riskLevel,
      recipients: securityEmails.length,
    });
  } catch (error: any) {
    logger.error('[FraudScan] Failed to notify security', {
      txId: tx.id,
      error: error.message,
    });
  }
}

/**
 * Main fraud scan function - call this for every payment transaction
 */
export async function scanTransaction(tx: Transaction) {
  try {
    logger.info('[FraudScan] Scanning transaction', {
      txId: tx.id,
      amount: `${(tx.amountCents / 100).toFixed(2)} ${tx.currency}`,
      type: tx.type,
    });
    
    // STEP 1: Get AI fraud analysis
    const analysis = await analyzeWithAI(tx);
    
    // STEP 2: Log to fraud_flags table
    await db.execute(sql`
      INSERT INTO fraud_flags (
        transaction_id,
        risk_score,
        risk_level,
        reasons,
        recommended_action,
        ai_model,
        created_at
      ) VALUES (
        ${tx.id},
        ${analysis.riskScore},
        ${analysis.riskLevel},
        ${JSON.stringify(analysis.reasons)},
        ${analysis.recommendedAction},
        'gemini-2.5-flash',
        NOW()
      )
    `);
    
    // STEP 3: Alert security team for high/critical risk
    if (analysis.riskLevel === 'high' || analysis.riskLevel === 'critical') {
      await notifySecurity(tx, analysis);
    }
    
    // STEP 4: Auto-block critical risk transactions
    if (analysis.riskLevel === 'critical') {
      logger.warn('[FraudScan] CRITICAL RISK - Auto-blocking transaction', {
        txId: tx.id,
        riskScore: analysis.riskScore,
      });
      
      await db.execute(sql`
        UPDATE payment_intents
        SET 
          status = 'blocked_fraud',
          fraud_blocked_at = NOW(),
          fraud_block_reason = ${analysis.reasons.join('; ')}
        WHERE nayax_transaction_id = ${tx.id}
      `);
    }
    
    logger.info('[FraudScan] Scan complete', {
      txId: tx.id,
      riskScore: analysis.riskScore,
      action: analysis.recommendedAction,
    });
    
    return analysis;
    
  } catch (error: any) {
    logger.error('[FraudScan] Scan failed', {
      txId: tx.id,
      error: error.message,
      stack: error.stack,
    });
    
    // Don't block transaction on scan failure (false negative is better than false positive)
    return {
      riskScore: 0,
      riskLevel: 'low' as const,
      reasons: ['Scan failed - transaction approved'],
      recommendedAction: 'approve' as const,
    };
  }
}

/**
 * Get fraud statistics for dashboard
 */
export async function getFraudStats() {
  try {
    const result = await db.execute(sql`
      SELECT 
        COUNT(*) FILTER (WHERE risk_level = 'low') as low_risk,
        COUNT(*) FILTER (WHERE risk_level = 'medium') as medium_risk,
        COUNT(*) FILTER (WHERE risk_level = 'high') as high_risk,
        COUNT(*) FILTER (WHERE risk_level = 'critical') as critical_risk,
        AVG(risk_score) as avg_risk_score,
        COUNT(*) FILTER (WHERE created_at > NOW() - INTERVAL '24 hours') as last_24h
      FROM fraud_flags
      WHERE created_at > NOW() - INTERVAL '30 days'
    `);
    
    return result.rows[0];
  } catch (error: any) {
    logger.error('[FraudScan] Failed to get stats', {
      error: error.message,
    });
    return null;
  }
}
